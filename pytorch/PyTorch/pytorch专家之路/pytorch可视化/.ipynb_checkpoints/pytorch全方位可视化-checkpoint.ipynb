{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beidongjiedeguang\\OneDrive\\a机器学习\\pytorch专家之路\\pytorch可视化\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models,datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.utils as vutils\n",
    "torch.__version__\n",
    "from torchsummary import summary # keras 风格\n",
    "\n",
    "from utils.utils import MyDataset, Net, normalize_invert\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "import os\n",
    "!cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tensorboard --logdir visual_weights` 即可启动，默认的端口是 6006,在浏览器中打开 http://localhost:6006/ 即可看到web页面。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 权重可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='./visual_weights')\n",
    "# !tensorboard --logdir visual_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # 定义权值初始化\n",
    "#     def initialize_weights(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 torch.nn.init.xavier_normal_(m.weight.data)\n",
    "#                 if m.bias is not None:\n",
    "#                     m.bias.data.zero_()\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 m.weight.data.fill_(1)\n",
    "#                 m.bias.data.zero_()\n",
    "#             elif isinstance(m, nn.Linear):\n",
    "#                 torch.nn.init.normal_(m.weight.data, 0, 0.01)\n",
    "#                 m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()     # 创建一个网络\n",
    "print(net)\n",
    "pretrained_dict = torch.load('./data/net_params.pkl')\n",
    "net.load_state_dict(pretrained_dict)\n",
    "\n",
    "# net = models.vgg16(pretrained=1)\n",
    "\n",
    "params = net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in params.items():\n",
    "    print('i={:<15}    j.size={}'.format(i,j.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过对比网络与参数的size，我们能看到：  \n",
    "`Conv2d(input,output,kernel_size)  \n",
    "conv.weight: (output,input, kernel_size) `   \n",
    "它们的input和output并不是在相同的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in params.items():\n",
    "    # 对当前网络而言，这里k总共会取两倍的层数，也就是10，这里我们只看卷积层权重的话，则有：\n",
    "#     if 'conv' in k and 'weight' in k:\n",
    "    if 'features.2.' in k and 'weight' in k:\n",
    "        # 这时v便是每个卷积层的权重，不含bias\n",
    "\n",
    "        c_int = v.size()[1]     # 输入层通道数\n",
    "        c_out = v.size()[0]     # 输出层通道数\n",
    "\n",
    "        # 以feature map为单位，绘制一组卷积核，一张feature map对应的卷积核个数为输出层通道数\n",
    "        for j in range(c_out):\n",
    "            print('k={}, v.size={}, j={}'.format(k, v.size(), j))\n",
    "            kernel_j = v[j, :, :, :].unsqueeze(1)       # 压缩维度，为make_grid制作输入\n",
    "            kernel_grid = vutils.make_grid(kernel_j, normalize=True, scale_each=True, nrow=c_int)   # 1*输入通道数, w, h\n",
    "            writer.add_image(k+'_split_in_channel', kernel_grid, global_step=j)     # j 表示feature map数\n",
    "\n",
    "        # 将一个卷积层的卷积核绘制在一起，每一行是一个feature map的卷积核\n",
    "        k_w, k_h = v.size()[-1], v.size()[-2]\n",
    "        kernel_all = v.view(-1, 1, k_w, k_h)\n",
    "        print(kernel_all.size())\n",
    "        kernel_grid = torchvision.utils.make_grid(kernel_all, normalize=True, scale_each=True, nrow=c_int)  # 1*输入通道数, w, h\n",
    "        writer.add_image(k + '_all', kernel_grid, global_step=666)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## feature map可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beidongjiedeguang\\OneDrive\\a机器学习\\pytorch专家之路\\pytorch可视化\n"
     ]
    }
   ],
   "source": [
    "!cd\n",
    "fileName = './feature_map'\n",
    "writer = SummaryWriter(log_dir=fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tensorboard --logdir feature_map` 即可启动，默认的端口是 6006,在浏览器中打开 http://localhost:6006/ 即可看到web页面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r'C:\\Users\\beidongjiedeguang\\Documents\\a_download\\hymenoptera_data'\n",
    "# 数据预处理\n",
    "normMean = [0.49139968, 0.48215827, 0.44653124]\n",
    "normStd = [0.24703233, 0.24348505, 0.26158768]\n",
    "\n",
    "Transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(normMean, normStd)\n",
    "])\n",
    "# 载入数据\n",
    "images = ImageFolder(image_path,transform=Transform)\n",
    "\n",
    "data_loader = DataLoader(dataset=images, batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
      "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
      "            Linear-5                  [-1, 120]          48,120\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vis_layer = 'conv1'\n",
    "pretrained_path = './data/net_params_72p.pkl'\n",
    "\n",
    "net = Net()\n",
    "pretrained_dict = torch.load(pretrained_path)\n",
    "net.load_state_dict(pretrained_dict)\n",
    "\n",
    "print(net)\n",
    "summary(net, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ad888f8f98>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 245,
       "width": 248
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = next(iter(data_loader))\n",
    "temp_x = img\n",
    "img.shape\n",
    "img = img.squeeze(0)\n",
    "img.shape\n",
    "label\n",
    "plt.imshow(img.numpy().transpose(1,2,0).clip(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 迁移到vgg16\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# net = models.resnet50(pretrained=True).to(device)\n",
    "net = models.vgg16(pretrained=True).to(device)\n",
    "\n",
    "for para in net.parameters():\n",
    "    para.requires_grad = False\n",
    "   \n",
    "# net.conv1 = torch.nn.Conv2d(1,64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "# net.fc = torch.nn.Linear(2048,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "              ReLU-2           [-1, 64, 32, 32]               0\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,928\n",
      "              ReLU-4           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-5           [-1, 64, 16, 16]               0\n",
      "            Conv2d-6          [-1, 128, 16, 16]          73,856\n",
      "              ReLU-7          [-1, 128, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]         147,584\n",
      "              ReLU-9          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-10            [-1, 128, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]         295,168\n",
      "             ReLU-12            [-1, 256, 8, 8]               0\n",
      "           Conv2d-13            [-1, 256, 8, 8]         590,080\n",
      "             ReLU-14            [-1, 256, 8, 8]               0\n",
      "           Conv2d-15            [-1, 256, 8, 8]         590,080\n",
      "             ReLU-16            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-17            [-1, 256, 4, 4]               0\n",
      "           Conv2d-18            [-1, 512, 4, 4]       1,180,160\n",
      "             ReLU-19            [-1, 512, 4, 4]               0\n",
      "           Conv2d-20            [-1, 512, 4, 4]       2,359,808\n",
      "             ReLU-21            [-1, 512, 4, 4]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n",
      "             ReLU-23            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-24            [-1, 512, 2, 2]               0\n",
      "           Conv2d-25            [-1, 512, 2, 2]       2,359,808\n",
      "             ReLU-26            [-1, 512, 2, 2]               0\n",
      "           Conv2d-27            [-1, 512, 2, 2]       2,359,808\n",
      "             ReLU-28            [-1, 512, 2, 2]               0\n",
      "           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n",
      "             ReLU-30            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-31            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "             ReLU-37                 [-1, 4096]               0\n",
      "          Dropout-38                 [-1, 4096]               0\n",
      "           Linear-39                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 0\n",
      "Non-trainable params: 138,357,544\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 4.84\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 532.65\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(net)\n",
    "summary(net, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-36-0d08138cccf9>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-36-0d08138cccf9>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    #     para\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "x = temp_x\n",
    "count = 0\n",
    "# for name, layer in net._modules.items():\n",
    "#     count, name,layer \n",
    "#     count +=1\n",
    "next(iter(net._modules.items))\n",
    "# for para in net.parameters():\n",
    "#     para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('conv1', torch.Size([1, 3, 32, 32]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 28, 28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('pool1', torch.Size([1, 3, 32, 32]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 16, 16])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('conv2', torch.Size([1, 3, 32, 32]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size 16 6 5 5, expected input[1, 3, 32, 32] to have 6 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-15857360b94a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"classifier\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;31m# 通过输出可以看到，layey(x) 就是将x放入在layer层的输出张量\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python3.6\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python3.6\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 338\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size 16 6 5 5, expected input[1, 3, 32, 32] to have 6 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "x = temp_x\n",
    "for name, layer in net._modules.items():\n",
    "\n",
    "    x = x.view(x.size(0), -1) if \"classifier\" in name else x\n",
    "    name,x.shape\n",
    "    layer(x).shape # 通过输出可以看到，layey(x) 就是将x放入在layer层的输出张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 6 3 5, but got 3-dimensional input of size [3, 32, 32] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3958e3a01041>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# 对x执行单层运算\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python3.6\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python3.6\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 338\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 6 3 5, but got 3-dimensional input of size [3, 32, 32] instead"
     ]
    }
   ],
   "source": [
    "for name, layer in net._modules.items():\n",
    "\n",
    "    # 为fc层预处理x\n",
    "    x = x.view(x.size(0), -1) if \"fc\" in name else x\n",
    "\n",
    "    # 对x执行单层运算\n",
    "    x = layer(x)\n",
    "    print(x.size())\n",
    "\n",
    "    # 由于__init__()相较于forward()缺少relu操作，需要手动增加\n",
    "    x = F.relu(x) if 'conv' in name else x\n",
    "\n",
    "    # 依据选择的层，进行记录feature maps\n",
    "    if name == vis_layer:\n",
    "        # 绘制feature maps\n",
    "        x1 = x.transpose(0, 1)  # C，B, H, W  ---> B，C, H, W\n",
    "        img_grid = vutils.make_grid(x1, normalize=True, scale_each=True, nrow=2)  # B，C, H, W\n",
    "        writer.add_image(vis_layer + '_feature_maps', img_grid, global_step=666)\n",
    "\n",
    "        # 绘制原始图像\n",
    "        img_raw = normalize_invert(img, normMean, normStd)  # 图像去标准化\n",
    "        img_raw = np.array(img_raw * 255).clip(0, 255).squeeze().astype('uint8')\n",
    "        writer.add_image('raw img', img_raw, global_step=666)  # j 表示feature map数\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
